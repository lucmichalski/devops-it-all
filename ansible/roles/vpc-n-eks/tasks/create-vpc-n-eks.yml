---
- name: Create aws vpc with eks - it'll take about 10 min ...
  terraform:
    binary_path: "/home/{{ lookup('env','USER') }}/bin/terraform"
    project_path: "{{ vpc_n_eks_terraform_dir }}"
    state: present 
    lock: yes
    backend_config:
      region: "us-east-1"
      bucket: "devopsitall-terraform-remote-state"
      key: "vpc-n-eks-terraform.tfstate"
      dynamodb_table:  "devopsitall-vpc-n-eks-terraform-remote-lock"
      encrypt: "true"
    force_init: true
  register: terraform_run

- name: Create user .kube dir
  file:
    path: "{{ user_home }}/.kube"
    state: directory
    mode: '0700'

- name: copy kubconfig file to user home .kube config file
  copy:
    src:  "{{ vpc_n_eks_terraform_dir }}/kubeconfig_kubernetes-{{ project_name }}"
    dest: "{{ user_home }}/.kube/config"
    owner: "{{ user_home.split('/')[-1] }}"
    group: "{{ user_home.split('/')[-1] }}"
    mode: "0600"
    force: yes

- name: update .ssh known_hosts with devopsitall haproxy server public rsa key
  lineinfile:
    regexp: "^haproxy.{{ domain_name }}"
    line: "haproxy.{{ domain_name }} {{ lookup('file', '{{ user_home }}/.ssh/devopsitall.pem.pub') }}"
    path: "{{ user_home }}/.ssh/known_hosts"
    state: present

#- name: Set AWS account (id, oidc_provider) variables
#  shell: "{{ playbook_dir }}/../shell/set_aws_account_variables.sh"

- name: Waiting for EKS status to change to active
  shell: aws eks describe-cluster --name kubernetes-devops-it-all|jq '.cluster.status'
  register: eks_status
  until: eks_status.stdout.find("ACTIVE") != -1
  retries: 10
  delay: 30

- name: management namespace create
  shell: kubectl create namespace management
  ignore_errors: true
